# Local-LLM-assistant
Running small but capable language models entirely offline
